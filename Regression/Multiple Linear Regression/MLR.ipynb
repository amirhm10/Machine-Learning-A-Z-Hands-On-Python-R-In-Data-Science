{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undrestanding P-Values\n",
    "- https://www.mathbootcamps.com/what-is-a-p-value/\n",
    "\n",
    "- https://www.wikihow.com/Calculate-P-Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data and train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"50_Startups.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0  165349.20       136897.80        471784.10    New York  192261.83\n",
       "1  162597.70       151377.59        443898.53  California  191792.06\n",
       "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
       "3  144372.41       118671.85        383199.62    New York  182901.99\n",
       "4  142107.34        91391.77        366168.42     Florida  166187.94"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\"State\"]\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "one_hot = OneHotEncoder(drop= \"first\")\n",
    "tranformer = ColumnTransformer([(\"onehot\", one_hot, categorical_features)],\n",
    "                              remainder=\"passthrough\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = tranformer.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>131876.90</td>\n",
       "      <td>99814.71</td>\n",
       "      <td>362861.36</td>\n",
       "      <td>156991.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134615.46</td>\n",
       "      <td>147198.87</td>\n",
       "      <td>127716.82</td>\n",
       "      <td>156122.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130298.13</td>\n",
       "      <td>145530.06</td>\n",
       "      <td>323876.68</td>\n",
       "      <td>155752.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120542.52</td>\n",
       "      <td>148718.95</td>\n",
       "      <td>311613.29</td>\n",
       "      <td>152211.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123334.88</td>\n",
       "      <td>108679.17</td>\n",
       "      <td>304981.62</td>\n",
       "      <td>149759.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101913.08</td>\n",
       "      <td>110594.11</td>\n",
       "      <td>229160.95</td>\n",
       "      <td>146121.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100671.96</td>\n",
       "      <td>91790.61</td>\n",
       "      <td>249744.55</td>\n",
       "      <td>144259.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93863.75</td>\n",
       "      <td>127320.38</td>\n",
       "      <td>249839.44</td>\n",
       "      <td>141585.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91992.39</td>\n",
       "      <td>135495.07</td>\n",
       "      <td>252664.93</td>\n",
       "      <td>134307.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119943.24</td>\n",
       "      <td>156547.42</td>\n",
       "      <td>256512.92</td>\n",
       "      <td>132602.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>114523.61</td>\n",
       "      <td>122616.84</td>\n",
       "      <td>261776.23</td>\n",
       "      <td>129917.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78013.11</td>\n",
       "      <td>121597.55</td>\n",
       "      <td>264346.06</td>\n",
       "      <td>126992.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94657.16</td>\n",
       "      <td>145077.58</td>\n",
       "      <td>282574.31</td>\n",
       "      <td>125370.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91749.16</td>\n",
       "      <td>114175.79</td>\n",
       "      <td>294919.57</td>\n",
       "      <td>124266.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86419.70</td>\n",
       "      <td>153514.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>122776.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76253.86</td>\n",
       "      <td>113867.30</td>\n",
       "      <td>298664.47</td>\n",
       "      <td>118474.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78389.47</td>\n",
       "      <td>153773.43</td>\n",
       "      <td>299737.29</td>\n",
       "      <td>111313.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73994.56</td>\n",
       "      <td>122782.75</td>\n",
       "      <td>303319.26</td>\n",
       "      <td>110352.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67532.53</td>\n",
       "      <td>105751.03</td>\n",
       "      <td>304768.73</td>\n",
       "      <td>108733.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77044.01</td>\n",
       "      <td>99281.34</td>\n",
       "      <td>140574.81</td>\n",
       "      <td>108552.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64664.71</td>\n",
       "      <td>139553.16</td>\n",
       "      <td>137962.62</td>\n",
       "      <td>107404.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75328.87</td>\n",
       "      <td>144135.98</td>\n",
       "      <td>134050.07</td>\n",
       "      <td>105733.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72107.60</td>\n",
       "      <td>127864.55</td>\n",
       "      <td>353183.81</td>\n",
       "      <td>105008.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66051.52</td>\n",
       "      <td>182645.56</td>\n",
       "      <td>118148.20</td>\n",
       "      <td>103282.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65605.48</td>\n",
       "      <td>153032.06</td>\n",
       "      <td>107138.38</td>\n",
       "      <td>101004.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61994.48</td>\n",
       "      <td>115641.28</td>\n",
       "      <td>91131.24</td>\n",
       "      <td>99937.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61136.38</td>\n",
       "      <td>152701.92</td>\n",
       "      <td>88218.23</td>\n",
       "      <td>97483.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63408.86</td>\n",
       "      <td>129219.61</td>\n",
       "      <td>46085.25</td>\n",
       "      <td>97427.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55493.95</td>\n",
       "      <td>103057.49</td>\n",
       "      <td>214634.81</td>\n",
       "      <td>96778.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46426.07</td>\n",
       "      <td>157693.92</td>\n",
       "      <td>210797.67</td>\n",
       "      <td>96712.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46014.02</td>\n",
       "      <td>85047.44</td>\n",
       "      <td>205517.64</td>\n",
       "      <td>96479.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28663.76</td>\n",
       "      <td>127056.21</td>\n",
       "      <td>201126.82</td>\n",
       "      <td>90708.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44069.95</td>\n",
       "      <td>51283.14</td>\n",
       "      <td>197029.42</td>\n",
       "      <td>89949.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20229.59</td>\n",
       "      <td>65947.93</td>\n",
       "      <td>185265.10</td>\n",
       "      <td>81229.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38558.51</td>\n",
       "      <td>82982.09</td>\n",
       "      <td>174999.30</td>\n",
       "      <td>81005.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28754.33</td>\n",
       "      <td>118546.05</td>\n",
       "      <td>172795.67</td>\n",
       "      <td>78239.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27892.92</td>\n",
       "      <td>84710.77</td>\n",
       "      <td>164470.71</td>\n",
       "      <td>77798.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23640.93</td>\n",
       "      <td>96189.63</td>\n",
       "      <td>148001.11</td>\n",
       "      <td>71498.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15505.73</td>\n",
       "      <td>127382.30</td>\n",
       "      <td>35534.17</td>\n",
       "      <td>69758.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22177.74</td>\n",
       "      <td>154806.14</td>\n",
       "      <td>28334.72</td>\n",
       "      <td>65200.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1000.23</td>\n",
       "      <td>124153.04</td>\n",
       "      <td>1903.93</td>\n",
       "      <td>64926.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1315.46</td>\n",
       "      <td>115816.21</td>\n",
       "      <td>297114.46</td>\n",
       "      <td>49490.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>135426.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>42559.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>542.05</td>\n",
       "      <td>51743.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>35673.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>116983.80</td>\n",
       "      <td>45173.06</td>\n",
       "      <td>14681.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1          2          3          4          5\n",
       "0   0.0  1.0  165349.20  136897.80  471784.10  192261.83\n",
       "1   0.0  0.0  162597.70  151377.59  443898.53  191792.06\n",
       "2   1.0  0.0  153441.51  101145.55  407934.54  191050.39\n",
       "3   0.0  1.0  144372.41  118671.85  383199.62  182901.99\n",
       "4   1.0  0.0  142107.34   91391.77  366168.42  166187.94\n",
       "5   0.0  1.0  131876.90   99814.71  362861.36  156991.12\n",
       "6   0.0  0.0  134615.46  147198.87  127716.82  156122.51\n",
       "7   1.0  0.0  130298.13  145530.06  323876.68  155752.60\n",
       "8   0.0  1.0  120542.52  148718.95  311613.29  152211.77\n",
       "9   0.0  0.0  123334.88  108679.17  304981.62  149759.96\n",
       "10  1.0  0.0  101913.08  110594.11  229160.95  146121.95\n",
       "11  0.0  0.0  100671.96   91790.61  249744.55  144259.40\n",
       "12  1.0  0.0   93863.75  127320.38  249839.44  141585.52\n",
       "13  0.0  0.0   91992.39  135495.07  252664.93  134307.35\n",
       "14  1.0  0.0  119943.24  156547.42  256512.92  132602.65\n",
       "15  0.0  1.0  114523.61  122616.84  261776.23  129917.04\n",
       "16  0.0  0.0   78013.11  121597.55  264346.06  126992.93\n",
       "17  0.0  1.0   94657.16  145077.58  282574.31  125370.37\n",
       "18  1.0  0.0   91749.16  114175.79  294919.57  124266.90\n",
       "19  0.0  1.0   86419.70  153514.11       0.00  122776.86\n",
       "20  0.0  0.0   76253.86  113867.30  298664.47  118474.03\n",
       "21  0.0  1.0   78389.47  153773.43  299737.29  111313.02\n",
       "22  1.0  0.0   73994.56  122782.75  303319.26  110352.25\n",
       "23  1.0  0.0   67532.53  105751.03  304768.73  108733.99\n",
       "24  0.0  1.0   77044.01   99281.34  140574.81  108552.04\n",
       "25  0.0  0.0   64664.71  139553.16  137962.62  107404.34\n",
       "26  1.0  0.0   75328.87  144135.98  134050.07  105733.54\n",
       "27  0.0  1.0   72107.60  127864.55  353183.81  105008.31\n",
       "28  1.0  0.0   66051.52  182645.56  118148.20  103282.38\n",
       "29  0.0  1.0   65605.48  153032.06  107138.38  101004.64\n",
       "30  1.0  0.0   61994.48  115641.28   91131.24   99937.59\n",
       "31  0.0  1.0   61136.38  152701.92   88218.23   97483.56\n",
       "32  0.0  0.0   63408.86  129219.61   46085.25   97427.84\n",
       "33  1.0  0.0   55493.95  103057.49  214634.81   96778.92\n",
       "34  0.0  0.0   46426.07  157693.92  210797.67   96712.80\n",
       "35  0.0  1.0   46014.02   85047.44  205517.64   96479.51\n",
       "36  1.0  0.0   28663.76  127056.21  201126.82   90708.19\n",
       "37  0.0  0.0   44069.95   51283.14  197029.42   89949.14\n",
       "38  0.0  1.0   20229.59   65947.93  185265.10   81229.06\n",
       "39  0.0  0.0   38558.51   82982.09  174999.30   81005.76\n",
       "40  0.0  0.0   28754.33  118546.05  172795.67   78239.91\n",
       "41  1.0  0.0   27892.92   84710.77  164470.71   77798.83\n",
       "42  0.0  0.0   23640.93   96189.63  148001.11   71498.49\n",
       "43  0.0  1.0   15505.73  127382.30   35534.17   69758.98\n",
       "44  0.0  0.0   22177.74  154806.14   28334.72   65200.33\n",
       "45  0.0  1.0    1000.23  124153.04    1903.93   64926.08\n",
       "46  1.0  0.0    1315.46  115816.21  297114.46   49490.75\n",
       "47  0.0  0.0       0.00  135426.92       0.00   42559.73\n",
       "48  0.0  1.0     542.05   51743.15       0.00   35673.41\n",
       "49  0.0  0.0       0.00  116983.80   45173.06   14681.40"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50, 5), (50,))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df_new[:, :-1]\n",
    "y = df_new[:,-1]\n",
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,\n",
    "                                                    y,\n",
    "                                                    test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9764007278613085, 0.9431552346720271)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_test, y_test), model.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEGCAYAAABYV4NmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAArqklEQVR4nO3de3xV1Zn/8c8jIMYLd7QQdEBF6rVSU2p1tCoWUNuC/nRKL0JHWqp1quNMGWV0qtX2JYqtrdOR1ooKjiKUIjKojRRUWm8QRORiESoUElCwXLSaYgLP74+1judCEpKQc0u+79frvNhrnb13nqNwnjx7rb22uTsiIiIt7YB8ByAiIq2TEoyIiGSFEoyIiGSFEoyIiGSFEoyIiGRF+3wHUCh69Ojhffv2zXcYIiJFZcmSJe+6e8+63lOCifr27UtFRUW+wxARKSpm9pf63tMlMhERyQolGBERyQolGBERyQolGBERyQolGBERyQrNIhMRKTKzl1YxsXw1m3ZU07tLCeOGDmDEwNJ8h7UXJRgRkSIye2kV42ctp7pmNwBVO6oZP2s5QMElGV0iExEpIhPLV3+cXBKqa3YzsXx18054ww1wzz0tENneVMGIiBSRTTuqm9Rfr+XL4ZRTku1rrtmPqOqmCkZEpIj07lLSpP69uMOwYcnkUlICH3zQQtGlU4IRESki44YOoKRDu7S+kg7tGDd0wL4PfuEFOOAAKC8P7d/+Fj78EA4+OAuR6hKZiEhRSQzkN2kWWW0tDBwIK1aEdv/+sHIldOiQ1ViVYEREisyIgaWNnzE2dy586UvJ9rPPwjnnZCWuTEowIiKt0d//Dr17w/btof35z8OCBeESWY5oDEZEpLWZOjUM3ieSy6uvwnPP5TS5gCoYEZHWY+dO6NIl2f7qV+HRR/MWjioYEZHW4Cc/SU8ua9bkNbmAKhgRkeL29tvQq1eyfd118NOf5i+eFKpgRESK1bhx6cll06aCSS6gBCMiUnzeegvM4K67QnvChHCHfmqyKQBZSzBm9oCZbTGzFSl9p5rZy2b2mplVmNmglPfGm9laM1ttZkNT+k8zs+XxvXvMzGJ/RzObHvtfMbO+KceMNrM18TU6W59RRCTnvvENOOaYZHv7drj++vzF04BsVjAPAcMy+u4EfujupwI/iG3M7ARgJHBiPOZeM0ushTAJGAv0j6/EOccA2939WOBu4I54rm7AzcBngUHAzWbWteU/nohIDi1bFqqWRx4J7cmTQ9WSOrBfYLKWYNx9IbAtsxvoFLc7A5vi9nDgMXff5e7rgLXAIDPrBXRy95fc3YGpwIiUY6bE7ZnA4FjdDAXmufs2d98OzGPvRCciUhzc4bzz4NRTQ7tz57B+2BVX5DWsxsj1LLJ/BcrN7C5Ccjsj9pcCL6fsVxn7auJ2Zn/imI0A7l5rZjuB7qn9dRyTxszGEqojjjrqqOZ+JhGR7Hj++fRlXZ54Ar785byF01S5HuS/CrjO3Y8ErgMmx36rY19voL+5x6R3ut/n7mXuXtazZ88GAxcRyZnaWhgwIJlcjj8eamqKKrlA7hPMaGBW3P4NYYwEQpVxZMp+fQiXzyrjdmZ/2jFm1p5wyW1bA+cSESl8s2eHVY7ffDO0Fy6EVaugffHdtpjrBLMJ+HzcPg9YE7fnACPjzLB+hMH8Re6+GXjfzE6P4yujgCdSjknMELsUWBDHacqBIWbWNQ7uD4l9IiKFq7oaDjsMLr44tAcPhj174Kyz8hvXfshaSjSzacA5QA8zqyTM7Po28PNYcfydOP7h7ivNbAawCqgFrnb3xEOnryLMSCsBno4vCJfXHjaztYTKZWQ81zYzuw1YHPe71d0zJxuIiBSOBx6AMWOS7WXL0h9nXKQs/NIvZWVlXlFRke8wRKQt2bEDuqbcRTFqFEyZUu/uhcjMlrh7WV3v6U5+EZF8mDAhPbm89VbRJZd9Kb5RIxGRYrZpE5Sm3Dlx/fUh2bRCSjAiIrly3XXws58l22+/DUcckbdwsk2XyEREsm3NmrDMSyK5/OQn4Q79VpxcQBWMiEj2uIenSk6fnuzbuRM6dar/mFZEFYyISDa8+ioccEAyuUydGhJOG0kuoApGRKRl7dkDZ58NL7wQ2j17woYNcNBB+Y0rD1TBiIi0lGefhXbtksll7lzYsqVNJhdQBSMisv9qasLilOvWhfanPgVLloRk04apghER2R+//S0ceGAyubzwArz2WptPLqAKRkSkeT74ALp3h127QvuCC+DJJ8N0ZAFUwYiINN2vfgWHHppMLitWwFNPKblkUAUjItJY27aFqiVhzBi4//78xVPgVMGIiDTGbbelJ5f165Vc9kEVjIhIQ6qqoE/Kg3VvvBF+9KP8xVNElGBEROrzL/8C//M/yfaWLeHGSWkUXSITEcm0enUYsE8kl5//PCzzouTSJFlLMGb2gJltMbMVGf3fM7PVZrbSzO5M6R9vZmvje0NT+k8zs+XxvXvMwjQNM+toZtNj/ytm1jflmNFmtia+RmfrM4pIK+MOF18Mn/xksu+99+Caa/IXUxHLZgXzEDAstcPMzgWGA6e4+4nAXbH/BGAkcGI85l4zS9ylNAkYC/SPr8Q5xwDb3f1Y4G7gjniubsDNwGeBQcDNZpby2DgRkTosXhwWp5w9O7QffTQknMMOy2tYxSxrCcbdFwLbMrqvAia4+664z5bYPxx4zN13ufs6YC0wyMx6AZ3c/SV3d2AqMCLlmMTzRWcCg2N1MxSY5+7b3H07MI+MRCci8rE9e+Czn4VBg0K7d+9wf8tXv5rfuFqBXI/BHAecFS9pPW9mn4n9pcDGlP0qY19p3M7sTzvG3WuBnUD3Bs4lIpJu3rywpMuiRaH9u9+FWWMHHpjfuFqJXM8iaw90BU4HPgPMMLOjgbpuf/UG+mnmMWnMbCzh8htHHXVUg4GLSCvy0UdwzDFQGX9/LSuDl1/W+mEtLNcVTCUwy4NFwB6gR+w/MmW/PsCm2N+njn5SjzGz9kBnwiW5+s61F3e/z93L3L2sp2aHiLQN06dDx47J5PLyy2H8pY7kMntpFWdOWEC/G57kzAkLmL20KsfBFrdcJ5jZwHkAZnYccCDwLjAHGBlnhvUjDOYvcvfNwPtmdnocXxkFPBHPNQdIzBC7FFgQx2nKgSFm1jUO7g+JfSLSlu3cGaYejxwZ2sOHJ8df6jB7aRXjZy2nakc1DlTtqGb8rOVKMk2QtUtkZjYNOAfoYWaVhJldDwAPxKnLHwGjY1JYaWYzgFVALXC1u++Op7qKMCOtBHg6vgAmAw+b2VpC5TISwN23mdltwOK4363unjnZQETakuOPhz/9Kdl+4430qch1mFi+muqa3Wl91TW7mVi+mhEDNazbGBa+36WsrMwrKiryHYaItKTVq/dOJI38zut3w5N1Dt4asG7CRfsdWmthZkvcvayu93Qnv4i0TmbpyeXFFxudXAB6dylpUr/sTQlGRFqXF15Ify5Lu3YhsXzuc006zbihAyjpkD7wX9KhHeOGDmiJKNsELXYpIkVr9tIqJpavZtOOanp3KeGF8YPTd3jzTejfv1nnToyzpJ5/3NABGn9pAiUYESlKiVle1TW7ueBPf2TSExOSb55yCixbtt8/Y8TAUiWU/aAEIyJFaWL5aqo/qmX9nV9K67/oxpk8+aP/l6eoJJXGYESkKA2bNy0tucwd8I/0vX4uq2oPymNUkkoVjIgUl5oaOPBA/iul6/jrZlJ9YEgsmuVVOFTBiEjxuPbatIUof3XGV+h7/dyPk4tmeRUWVTAiUvjeew86d07vq63liNffplSzvAqWEoyIFLYLL4Snn062f/lL+M53AM3yKnRKMCJSmKqqoE+f9L49e9JvopSCpjEYESk8/fqlJ5f/+79wN76SS1FRBSMihWPlSjjppPQ+LchbtFTBiEhhMEtPLosXK7kUOSUYEcmv555Lv/R1yCEhsZTVuQK8FBFdIhOR/MkcU/nzn+Hoo/MTi7Q4VTAiknvTpqUnl0GDQtWi5NKqqIIRkdzZsyc8nyXVu+9C9+75iUeyKmsVjJk9YGZbzGxFHe9938zczHqk9I03s7VmttrMhqb0n2Zmy+N795iFX3vMrKOZTY/9r5hZ35RjRpvZmvgana3PKCJNcMcd6cnl8stD1aLk0mpls4J5CPgFMDW108yOBL4AbEjpOwEYCZwI9AZ+b2bHuftuYBIwFngZeAoYBjwNjAG2u/uxZjYSuAP4ipl1A24GygAHlpjZHHffnsXPKiL12bULDspY4fjDD6FEi1K2dlmrYNx9IbCtjrfuBv6D8OWfMBx4zN13ufs6YC0wyMx6AZ3c/SV3d0KyGpFyzJS4PRMYHKubocA8d98Wk8o8QlISkVy78sr05HLLLaFqUXJpE3I6BmNmXwaq3H2Zpc8eKSVUKAmVsa8mbmf2J47ZCODutWa2E+ie2l/HMZnxjCVURxx11FHN+1AisrcdO6Br1/S+3bvhAM0rakty9n/bzA4GbgR+UNfbdfR5A/3NPSa90/0+dy9z97KePXvWtYuINNV556UnlwcfDFWLkkubk8sK5higH5CoXvoAr5rZIEKVcWTKvn2ATbG/Tx39pBxTaWbtgc6ES3KVwDkZxzzXsh9FRPaycSNkXgnQnfhtWs5+pXD35e5+uLv3dfe+hETwaXd/G5gDjIwzw/oB/YFF7r4ZeN/MTo/jK6OAJ+Ip5wCJGWKXAgviOE05MMTMuppZV2BI7BORbPnEJ9KTS3m5kotkr4Ixs2mESqKHmVUCN7v75Lr2dfeVZjYDWAXUAlfHGWQAVxFmpJUQZo8lHgwxGXjYzNYSKpeR8VzbzOw2YHHc71Z3r2uygYjsr2XL4NRT0/uUWCQy118GAMrKyryioiLfYYhkzeylVUxsyac/Zi7zsnTp3slGWj0zW+LudS4cp1E3kTZg9tIqxs9aTtWOahyo2lHN+FnLmb20quknmzcvPbn07BmqFiUXyaAEI9IGTCxfTXXN7rS+6prdTCxf3bQTff3rMGRIsr1+PWzZsv8BSquktchE2oBNO6qb1L+X116DgQOT7fPPD5WMSAOUYETagN5dSqiqI5n07rKPO+rd4dxz4fnnQ7trV9i0ae+lX0TqoEtkIm3AuKEDKOmQvopxSYd2jBs6oP6Dnn8+3ByZSC5z5sC2bUou0miqYETagMRssUbNIquthRNOgDVrQvvEE8Mlsvb6upCm0d8YkTZixMDSfU9LfvxxuOSSZHvhQjjrrOwGJq2WEoyIQHV1mG78wQeh/YUvhLvxM+91EWkCjcGItHWTJ8PBByeTy7Jl8MwzSi6y31TBiLRV27dDt27J9qhRMGVK/fuLNJEqGJG26Pbb05PLW28puUiLUwUj0pZs2gSlKQP9118PEyZ83Gzx9cqkTVOCEWkrLroInnoq2X7nHTj88I+TStWOaozk0/kS65UBSjLSLLpEJtLavfJKGLBPJJef/jTcoR+TS2IRTNj70a/NWq9MJFIFI9Ja1fWY4i1bwnTkqK5FMDM1er0ykQyqYERao7lz05PL978fEk5KcoHGJY99rlcmUg9VMCKtyZ490C59zTH+9jc45JA6d69vEcyEfa5XJtIAVTAircXkyenJ5Wc/C1VLPckF6l4EM3F7ZWmXEm6/5GQN8EuzNVjBmNl/s/e438fc/ZoGjn0A+CKwxd1Pin0TgS8BHwF/Bv7Z3XfE98YDY4DdwDXuXh77TwMeAkqAp4Br3d3NrCMwFTgN+CvwFXdfH48ZDdwUQ/mRu2uCv7Ref/87lGRcxqqpadTilE1aBFOkicy93vyR+KKuV0Nf3GZ2NvA3YGpKghkCLHD3WjO7I57jejM7AZgGDAJ6A78HjnP33Wa2CLgWeJmQYO5x96fN7LvAKe5+pZmNBC5296+YWTegAigjJMclwGnuvr2hz1JWVuYVFRUN7SJSeG69FW6+OdmePh3+6Z/yF4+0OWa2xN3L6nqvwV9x9uc3f3dfaGZ9M/qeSWm+DFwat4cDj7n7LmCdma0FBpnZeqCTu78EYGZTgRHA0/GYW+LxM4FfmJkBQ4F57r4tHjMPGEZIYCKtw44d4eFfqfbs0fphUlAaNQZjZj3N7C4ze8rMFiRe+/mzryAkCoBSYGPKe5WxrzRuZ/anHePutcBOoHsD59qLmY01swozq9i6det+fRiRnPn2t9OTy7PPhrEWJRcpMI2dRfYIMB24CLgSGA00+xvZzG4EauN5ITmumMob6G/uMemd7vcB90G4RNZAyCL5V1UFffok24cfHu7GFylQjZ1F1t3dJwM17v68u18BnN6cHxjHdb4IfN2TA0CVwJEpu/UBNsX+PnX0px1jZu2BzsC2Bs4lUrzOPz89uSxbpuQiBa+xCaYm/rnZzC4ys4Gkf/E3ipkNA64HvuzuH6a8NQcYaWYdzawf0B9Y5O6bgffN7PQ4vjIKeCLlmMQkhEsJkwccKAeGmFlXM+sKDIl9IsVn1apw6Wv+/NA+44xwOeyUU/Ibl0gjNPYS2Y/MrDPw78B/A52A6xo6wMymAecAPcysErgZGA90BOaFfMHL7n6lu680sxnAKsKls6vdPbF+xVUkpyk/TXLcZjLwcJwQsA0YCeDu28zsNmBx3O/WxIC/SFH5h3+ADRuS7fXrQ59IkWhwmnJbomnKUjD++Ec466xk+xvfgIcfzl88Ig1o9jTllBMcB0wCjnD3k8zsFMJlrh+1YJwibVtdi1P+9a/pDwYTKSKNHYP5NeHyVg2Au79OvCQlIi1g9uz05PKf/xkSjpKLFLHGjsEc7O6LLH2efW0W4hFpW3bv3ntJlw8/3HvpF5Ei1NgK5l0zO4Z4P4mZXQpszlpUIm3BpEnpyeXee0PVouQirURjK5irCTckftLMqoB1wNezFpVIa1ZdDQcfnN5XW7v3MvsiRa5RFYy7v+Xu5wM9gU8Sph//YxbjEmmdbropPbnMmhWqFiUXaYX2tVx/J0L1Ukq4wfH3sf19YBnJpV5EpCHbtkH37ul9WpxSWrl9VTAPAwOA5cC3gWeAy4AR7j48y7GJtA6jRqUnl4ULtTiltAn7GoM52t1PBjCz+4F3gaPc/f2sRyZS7DZsSL/z/qij4C9/yV88Ijm2rwomsQYZcemWdUouIo1w1lnpyWXlSiUXaXP2VcF8yszei9sGlMS2Ae7unbIanUixef11+NSnku3zzksuVAnMXlqlxxNLm7GvJ1pqaotIY33iE+lL6G/cmLbE/uylVYyftZzqmrCOa9WOasbPWg6gJCOtUmNvtBSR+tx7bxiwTySXK64Ig/h90p9oMbF89cfJJaG6ZjcTy1fnKlKRnGrsjZYikqmuxSm3b4cuXercfdOO6ib1ixQ7VTAizfFv/5aeXE46KSScepILQO8udS8BU1+/SLFTBSPSFLt2wUEHpfe99x4cdtg+Dx03dEDaGAxASYd2jBs6oKWjFCkIqmBEGuuCC9KTy8iRoWppRHKBMJB/+yUnU9qlBANKu5Rw+yUna4BfWq2sVTBm9gDwRWCLu58U+7oB04G+wHrgn9x9e3xvPDAG2A1c4+7lsf80ko9Mfgq41t3dzDoCU4HTgL8CX3H39fGY0cBNMZQfufuUbH1OaQO2b9/7uSw1NXsvs98IIwaWKqFIm5HNCuYhYFhG3w3AfHfvD8yPbczsBMIDzE6Mx9xrZokp0pOAsUD/+Eqccwyw3d2PBe4G7ojn6gbcDHwWGATcbGZds/D5pC3o0yc9udx8c6hampFcRNqarCUYd18IbMvoHg4kqokpwIiU/sfcfZe7rwPWAoPMrBfQyd1fcncnVCwj6jjXTGCwhSeiDQXmufu2WB3NY+9EJ9KwdevC1OOqqmTfnj1wyy15C0mk2OR6DOYId98MEP88PPaXAhtT9quMfaVxO7M/7Rh3rwV2At0bONdezGysmVWYWcXWrVv342NJq2IGRx+dbE+ZosUpRZqhUAb56/qX6w30N/eY9E73+9y9zN3Levbs2ahApRVbtGjvJOIeVkMWkSbL9YXkd8ysl7tvjpe/tsT+SuDIlP36AJtif586+lOPqTSz9kBnwiW5SsID0VKPea5lP4bkS9bW8spMLAsWwLnn7v95RdqwXFcwc4DRcXs04SFmif6RZtbRzPoRBvMXxcto75vZ6XF8ZVTGMYlzXQosiOM05cAQM+saB/eHxD4pcom1vKp2VOMk1/KavbRqn8fW6/HH665alFxE9ls2pylPI1QSPcyskjCzawIww8zGABsIDy/D3Vea2QxgFVALXB0fDwBwFclpyk/HF8Bk4GEzW0uoXEbGc20zs9uAxXG/W909c7KBFKGG1vJqVhWTmVhWroQTTtiPCEUklYVf+qWsrMwrKiryHYY0oN8NT9Y5mGbAugkXNf5E06bB176WbHfoAB99tL/hibRJZrbE3cvqek+T+aVo9O5SQlUdC0M2ei2vPXugXcYTKN59N/1xxiLSYgplFpnIPo0bOoCSDukJotFreU2YkJ5cLr88jLUouYhkjSoYKRqJcZYmzSKra3HKDz+EEq1gLJJtSjBSVJq0ltd3vgP33Zds33JLWOpFRHJCCUZanx07oGvG8nO1tXuPv4hIVmkMRorW7KVVnDlhAf1ueJIzJywI98Oce256cnnwwTDWouQiknOqYKQoJW66TNwX4xv+wohPD07fSVPwRfJKFYwUpdSbLr/zykxenHRF8s3yciUXkQKgCkaK0qYd1fT823YW/8/laf39rp/LuiFD8hSViKRSgpGi9OMXp/C1P/zm4/Znrp7K1kO7UdrYmy5FJOuUYKS4/PnPcOyxJBZ6uf2cb/Krz14KNOGmSxHJCY3BSPH42tfg2GM/bj75/ErmDr0cA0q7lHD7JSfrefciBUQVjBS+pUvh059Oth98EL75TS4CLjpbqx+LFColGClcieeyPP98aHfuDJs3a5kXkSKhS2RSmJ57Dg44IJlcnngi3KGv5CJSNFTBSGGprQ0P/VqzJrSPPx5efx3a66+qSLFRBSOF4/HHw8O/Esll4UJYtUrJRaRI6V+u5N+HH8Lhh8MHH4T2F74Q7sbPfKSxiBSVvFQwZnadma00sxVmNs3MDjKzbmY2z8zWxD+7puw/3szWmtlqMxua0n+amS2P791jFr6RzKyjmU2P/a+YWd88fExpjPvvh0MOSSaXZcvgmWeUXERagZwnGDMrBa4Bytz9JKAdMBK4AZjv7v2B+bGNmZ0Q3z8RGAbca2aJpXEnAWOB/vE1LPaPAba7+7HA3cAdOfho0hTbt4ck8u1vh/aoUWHW2Cmn5DcuEWkx+RqDaQ+UmFl74GBgEzAcmBLfnwKMiNvDgcfcfZe7rwPWAoPMrBfQyd1fcncHpmYckzjXTGBworqRAnD77dCtW7L91lswZUr9+4tIUcp5gnH3KuAuYAOwGdjp7s8AR7j75rjPZuDweEgpsDHlFJWxrzRuZ/anHePutcBOYK+Hr5vZWDOrMLOKrVu3tswHlPpt2hSqlv/8z9C+/vpQtfTrl9+4RCQr8nGJrCuhwugH9AYOMbNvNHRIHX3eQH9Dx6R3uN/n7mXuXtazZ8+GA5f9c+21UJqyjMvbb8OECfmLR0SyLh+XyM4H1rn7VnevAWYBZwDvxMtexD+3xP0rgSNTju9DuKRWGbcz+9OOiZfhOgPbsvJppGFvvhmqlnvuCe2f/jRULUcckd+4RCTr8pFgNgCnm9nBcVxkMPAGMAcYHfcZDTwRt+cAI+PMsH6EwfxF8TLa+2Z2ejzPqIxjEue6FFgQx2kkV9zhsstgQMrqxjt3wnXX5S8mEcmpnN8H4+6vmNlM4FWgFlgK3AccCswwszGEJHRZ3H+lmc0AVsX9r3b33fF0VwEPASXA0/EFMBl42MzWEiqXkTn4aJKwZAmUlSXbU6fC5ZfXv7+ItEqmX+yDsrIyr6ioyHcYxW3PHjjrLHjxxdDu2RM2bICDDspvXCKSNWa2xN3L6npPS8VIy5g/H9q1SyaXJ5+ELVuUXETaMC0VI/unpgaOOw7Wrw/tU0+FioqQbESkTVMFI803cyYceGAyubz4Yng4mJKLiKAKRprjgw+ga9dQvQBceCHMnav1w0QkjSoYaZpJk+DQQ5PJZcWKMN6i5CIiGVTBSOP89a/Qo0eyPWZMWAlZRKQeqmBk3269NT25rF+v5CIi+6QKRuq3cSMcdVSyfdNNcNtt+YtHRIqKEozU7bvfDeMtCVu3plcxIiL7oEtkku6NN8KAfSK53HNPWFdMyUVEmkgVjATucPHF8MQTyb733w8zxkREmkEVjMCiRXDAAcnk8uijIeEouYjIflAF05bt2QOnnw6LF4d2aWl4fPGBB+Y3LhFpFVTBtFXl5WFJl0RyKS+HykolFxFpMapg2pqPPoK+fWHz5tD+zGfg5ZfDJTIRkRakb5W25LHHoGPHZHJ55ZXk+IuISAtTBdMW/O1vcNhhyfbw4fD441o/TESySr+6tna/+EV6cnnjDZg9W8lFRLIuLwnGzLqY2Uwz+5OZvWFmnzOzbmY2z8zWxD+7puw/3szWmtlqMxua0n+amS2P791jFr41zayjmU2P/a+YWd88fMz8evfdkES+973QvvLKMPX4k5/Mb1wi0mbkq4L5OfA7d/8k8CngDeAGYL679wfmxzZmdgIwEjgRGAbca2aJJ1pNAsYC/eNrWOwfA2x392OBu4E7cvGhCsZNN0HPnsn2xo3py76IiORAzhOMmXUCzgYmA7j7R+6+AxgOTIm7TQFGxO3hwGPuvsvd1wFrgUFm1gvo5O4vubsDUzOOSZxrJjA4Ud20an/5S6hafvzj0P7hD0PV0qdPfuMSkTYpHxXM0cBW4EEzW2pm95vZIcAR7r4ZIP55eNy/FNiYcnxl7CuN25n9ace4ey2wE+ieGYiZjTWzCjOr2Lp1a0t9vvz41rfC9OOEd9+FH/wgb+GIiOQjwbQHPg1McveBwAfEy2H1qKvy8Ab6GzomvcP9Pncvc/eynqmXlIrJypWhapk8ObQnTQpVS/e98qmISE7lI8FUApXu/kpszyQknHfiZS/in1tS9j8y5fg+wKbY36eO/rRjzKw90BnY1uKfJJ/c4cIL4aSTQrtDhzAd+cor8xuXiEiU8wTj7m8DG81sQOwaDKwC5gCjY99oILGs7xxgZJwZ1o8wmL8oXkZ738xOj+MrozKOSZzrUmBBHKdpHV56Kdwc+fTToT1jRrhD/5BD8huXiEiKfN1o+T3gETM7EHgL+GdCspthZmOADcBlAO6+0sxmEJJQLXC1u++O57kKeAgoAZ6OLwgTCB42s7WEymVkLj5U1u3eDaedBsuWhXa/frB6daheREQKjLWmX+z3R1lZmVdUVOQ7jPo99RRcdFGy/fvfw+DB+YtHRAQwsyXuXlbXe1oqptDt2hWmGb/7bmifeSYsXKj1w0Sk4OlbqpA9/DAcdFAyuSxeDH/8o5KLiBQFVTCF6L33oHPnZPuyy2D6dK0fJiJFRb8KF5q7705PLm++GWaJKbmISJFRBVMo3nkHPvGJZPuaa+DnP89fPCIi+0kVTCG4/vr05FJVpeQiIkVPCSaf1q0Ll77uvDO0f/zjcId+7975jUtEpAXoElm+jB4NU6cm29u2Qdeu9e8vIlJkVMHk2uuvh6olkVx+/etQtSi5iEgrowomV9zhC1+A+fND+9BDYcsWKCnJb1wiIlmiCiYX/vCHcHNkIrk8/ji8/76Si4i0aqpgsqm2Fk45Bd54I7SPOy48v6W9/rOLSOunCiZb5swJqxwnkstzz4WVj5VcRKSN0LddS6uuhl69YOfO0D7nHFiwQHfii0ibowqmJT34IBx88MfJ5dlp5Zw59L/oN/4pzpywgNlLq/IcoIhI7ijBtIQdO0KFcsUVof21rzH71Uq+u3IPVTuqcaBqRzXjZy1XkhGRNkMJZn/V1KTfw7J2LTzyCBPLV1Ndsztt1+qa3UwsX53jAEVE8iNvCcbM2pnZUjObG9vdzGyema2Jf3ZN2Xe8ma01s9VmNjSl/zQzWx7fu8csDHSYWUczmx77XzGzvln7IO3ahde//3u41+WYYwDYtKO6zt3r6xcRaW3yWcFcC7yR0r4BmO/u/YH5sY2ZnQCMBE4EhgH3mlm7eMwkYCzQP76Gxf4xwHZ3Pxa4G7gja5/igAPCdOS77krr7t2l7ntc6usXEWlt8pJgzKwPcBFwf0r3cGBK3J4CjEjpf8zdd7n7OmAtMMjMegGd3P0ld3dgasYxiXPNBAYnqptcGTd0ACUd2qX1lXRox7ihA3IZhohI3uSrgvkZ8B/AnpS+I9x9M0D88/DYXwpsTNmvMvaVxu3M/rRj3L0W2Al0zwzCzMaaWYWZVWzdunU/P1K6EQNLuf2SkyntUoIBpV1KuP2SkxkxsHSfx4qItAY5vw/GzL4IbHH3JWZ2TmMOqaPPG+hv6Jj0Dvf7gPsAysrK9np/f40YWKqEIiJtVj5utDwT+LKZXQgcBHQys/8F3jGzXu6+OV7+2hL3rwSOTDm+D7Ap9vepoz/1mEozaw90BrZl6wOJiMjecn6JzN3Hu3sfd+9LGLxf4O7fAOYAo+Nuo4En4vYcYGScGdaPMJi/KF5Ge9/MTo/jK6Myjkmc69L4M1q8QhERkfoV0lIxE4AZZjYG2ABcBuDuK81sBrAKqAWudvfEDSZXAQ8BJcDT8QUwGXjYzNYSKpeRufoQIiISmH6xD8rKyryioiLfYYiIFBUzW+LuZXW9pzv5RUQkK1TBRGa2FfhLI3btAbyb5XD2l2JsGYqxZSjGllGoMf6Du/es6w0lmCYys4r6ysFCoRhbhmJsGYqxZRRDjJl0iUxERLJCCUZERLJCCabp7st3AI2gGFuGYmwZirFlFEOMaTQGIyIiWaEKRkREskIJRkREsqJNJ5hCf6qmmXUxs5lm9icze8PMPleAMV5nZivNbIWZTTOzg/Ido5k9YGZbzGxFSl9OYjKz0fFnrDGzxHp4jY1xYvx//bqZPW5mXQotxpT3vm9mbmY9CjFGM/tejGOlmd1ZaDGa2alm9rKZvWbhkSGD8hlj1rh7m30B/wY8CsyN7TuBG+L2DcAdcfsEYBnQEegH/BloF99bBHyO8IiAp4ELYv93gV/G7ZHA9GbENwX4Vtw+EOhSSDESnruzDiiJ7RnAN/MdI3A28GlgRUpf1mMCugFvxT+7xu2uTYhxCNA+bt9RiDHG/iOBcsKNyT0KLUbgXOD3QMfYPrwAY3wm5WdcCDyXzxiz9cr7l3y+XoTl/ecD55FMMKuBXnG7F7A6bo8HxqccWx7/R/cC/pTS/1XgV6n7xO32hDtwrQnxdSJ8eVtGfyHFmHiwW7d4/FzCl2TeYwT6ZvyDznpMqfvE934FfLWxMWa8dzHwSCHGSHhK7KeA9SQTTMHESPhF5/w69iukGMuBr6T8vEfzHWM2Xm35EtnPKICnajbgaGAr8KCFy3j3m9khhRSju1cBdxFWv94M7HT3ZwopxhS5iKm+czXHFSRXBy+YGM3sy0CVuy/LeKtgYgSOA86Kl4ueN7PPFGCM/wpMNLONhH9D4wswxv3WJhOMpTxVs7GH1NHnDfQ3dExjtSeU1ZPcfSDwAeHSTsHEaGEcYzihlO8NHGJm3yikGBuhJWNqkVjN7EbCoykeKaQYzexg4EbgB3W9XQgxRu0Jl4ROB8YRHgNiBRbjVcB17n4kcB3hESPN/XlZ/fu4P9pkgiH5VM31wGPAeZbyVE0Aa7mnamLNe6pmJVDp7q/E9kxCwimkGM8H1rn7VnevAWYBZxRYjAm5iKm+czVaHIj9IvB1j9c1CijGYwi/TCyL/3b6AK+a2ScKKMbEeWd5sIhwlaJHgcU4mvDvBeA3QGKQv5Bi3H+5vB5XiC/gHJJjMBNJHwi+M26fSPrA21skB94WE35TSgy8XRj7ryZ94G1GM2L7AzAgbt8S4yuYGIHPAiuBg+O5pwDfK4QY2fuad9ZjIoxFrSP89tw1bndrQozDCA/W65mxX8HEmPHeepJjMAUTI3AlcGvcPo5wmcgKLMY3gHPi9mBgSb7/O2bjlfcv+Hy/SE8w3QkD/2vin91S9ruRMKNjNXH2RuwvA1bE935BcnWEgwi/mawlzP44uhmxnQpUAK8Ds+NfkkKL8YfAn+L5H47/MPIaIzCNMCZUQ/gtbkyuYiKMnayNr39uYoxrCV+Gr8XXLwstxoz31xMTTCHFSJhx+b/xZ74KnFeAMf4jsISQTF4BTstnjNl6aakYERHJirY6BiMiIlmmBCMiIlmhBCMiIlmhBCMiIlmhBCMiIlmhBCPSQsxsd1wdd4WZ/Sbe+d7ccz1kZpfG7fvN7IQG9j3HzM5oxs9Yn7oaskhLU4IRaTnV7n6qu58EfES44e9jZtauOSd192+5+6oGdjmHsIKCSEFRghHJjj8Ax8bq4lkzexRYbuEZRBPNbLGF5758B8CCX5jZKjN7kuRinJjZc2ZWFreHmdmrZrbMzObHZ39cCVwXq6ezzKynmf02/ozFZnZmPLa7mT0TF0/9FXWvVSXSYtrnOwCR1iauB3UB8LvYNQg4yd3XmdlYwqrTnzGzjsALZvYMMBAYAJwMHEFYMuaBjPP2BH4NnB3P1c3dt5nZL4G/uftdcb9Hgbvd/Y9mdhRhOffjgZuBP7r7rWZ2ETA2q/8hpM1TghFpOSVm9lrc/gNhhdwzgEXuvi72DwFOSYyvEBYm7E94KNU0d98NbDKzBXWc/3RgYeJc7l7fop/nAyfEBx4CdDKzw+LPuCQe+6SZbW/exxRpHCUYkZZT7e6npnbEL/kPUruA77l7ecZ+F7LvpdStEftAuPT9OXevriMWrQ0lOaMxGJHcKgeuMrMOAGZ2XHyQ3EJgZByj6UV47G+ml4DPm1m/eGy32P8+cFjKfs8A/5JomNmpcXMh8PXYdwFh8VSRrFGCEcmt+wnjK6+a2QrCY2zbA48TVnpeDkwCns880N23EsZNZpnZMmB6fOv/gIsTg/zANUBZnESwiuRsth8CZ5vZq4RLdRuy9BlFALSasoiIZIcqGBERyQolGBERyQolGBERyQolGBERyQolGBERyQolGBERyQolGBERyYr/DyrhhnGCf3KFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(predictions, y_test)\n",
    "plt.plot(y_test, y_test, color=\"red\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward Eliminations features\n",
    "\n",
    "**we have to add x0 = 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.append(arr = np.ones(shape=(50,1)), values = x, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 6)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_opt = x[:, [0, 1, 2, 3, 4, 5]]\n",
    "regressor_ols = sm.OLS(endog = y, exog = x_opt).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   169.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 02 Jan 2021</td> <th>  Prob (F-statistic):</th> <td>1.34e-27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:25:49</td>     <th>  Log-Likelihood:    </th> <td> -525.38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    44</td>      <th>  BIC:               </th> <td>   1074.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.013e+04</td> <td> 6884.820</td> <td>    7.281</td> <td> 0.000</td> <td> 3.62e+04</td> <td>  6.4e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>  198.7888</td> <td> 3371.007</td> <td>    0.059</td> <td> 0.953</td> <td>-6595.030</td> <td> 6992.607</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>  -41.8870</td> <td> 3256.039</td> <td>   -0.013</td> <td> 0.990</td> <td>-6604.003</td> <td> 6520.229</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.8060</td> <td>    0.046</td> <td>   17.369</td> <td> 0.000</td> <td>    0.712</td> <td>    0.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0270</td> <td>    0.052</td> <td>   -0.517</td> <td> 0.608</td> <td>   -0.132</td> <td>    0.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.0270</td> <td>    0.017</td> <td>    1.574</td> <td> 0.123</td> <td>   -0.008</td> <td>    0.062</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.782</td> <th>  Durbin-Watson:     </th> <td>   1.283</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.948</td> <th>  Prob(JB):          </th> <td>2.41e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.572</td> <th>  Cond. No.          </th> <td>1.45e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.45e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.945\n",
       "Method:                 Least Squares   F-statistic:                     169.9\n",
       "Date:                Sat, 02 Jan 2021   Prob (F-statistic):           1.34e-27\n",
       "Time:                        11:25:49   Log-Likelihood:                -525.38\n",
       "No. Observations:                  50   AIC:                             1063.\n",
       "Df Residuals:                      44   BIC:                             1074.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.013e+04   6884.820      7.281      0.000    3.62e+04     6.4e+04\n",
       "x1           198.7888   3371.007      0.059      0.953   -6595.030    6992.607\n",
       "x2           -41.8870   3256.039     -0.013      0.990   -6604.003    6520.229\n",
       "x3             0.8060      0.046     17.369      0.000       0.712       0.900\n",
       "x4            -0.0270      0.052     -0.517      0.608      -0.132       0.078\n",
       "x5             0.0270      0.017      1.574      0.123      -0.008       0.062\n",
       "==============================================================================\n",
       "Omnibus:                       14.782   Durbin-Watson:                   1.283\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.266\n",
       "Skew:                          -0.948   Prob(JB):                     2.41e-05\n",
       "Kurtosis:                       5.572   Cond. No.                     1.45e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.45e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.946</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   217.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 02 Jan 2021</td> <th>  Prob (F-statistic):</th> <td>8.49e-29</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:27:52</td>     <th>  Log-Likelihood:    </th> <td> -525.38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1061.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    45</td>      <th>  BIC:               </th> <td>   1070.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.011e+04</td> <td> 6647.870</td> <td>    7.537</td> <td> 0.000</td> <td> 3.67e+04</td> <td> 6.35e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>  220.1585</td> <td> 2900.536</td> <td>    0.076</td> <td> 0.940</td> <td>-5621.821</td> <td> 6062.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.8060</td> <td>    0.046</td> <td>   17.606</td> <td> 0.000</td> <td>    0.714</td> <td>    0.898</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0270</td> <td>    0.052</td> <td>   -0.523</td> <td> 0.604</td> <td>   -0.131</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0270</td> <td>    0.017</td> <td>    1.592</td> <td> 0.118</td> <td>   -0.007</td> <td>    0.061</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.758</td> <th>  Durbin-Watson:     </th> <td>   1.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.948</td> <th>  Prob(JB):          </th> <td>2.53e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.563</td> <th>  Cond. No.          </th> <td>1.40e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.946\n",
       "Method:                 Least Squares   F-statistic:                     217.2\n",
       "Date:                Sat, 02 Jan 2021   Prob (F-statistic):           8.49e-29\n",
       "Time:                        11:27:52   Log-Likelihood:                -525.38\n",
       "No. Observations:                  50   AIC:                             1061.\n",
       "Df Residuals:                      45   BIC:                             1070.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.011e+04   6647.870      7.537      0.000    3.67e+04    6.35e+04\n",
       "x1           220.1585   2900.536      0.076      0.940   -5621.821    6062.138\n",
       "x2             0.8060      0.046     17.606      0.000       0.714       0.898\n",
       "x3            -0.0270      0.052     -0.523      0.604      -0.131       0.077\n",
       "x4             0.0270      0.017      1.592      0.118      -0.007       0.061\n",
       "==============================================================================\n",
       "Omnibus:                       14.758   Durbin-Watson:                   1.282\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.172\n",
       "Skew:                          -0.948   Prob(JB):                     2.53e-05\n",
       "Kurtosis:                       5.563   Cond. No.                     1.40e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_opt = x[:, [0, 1, 3, 4, 5]]\n",
    "regressor_ols = sm.OLS(endog = y, exog = x_opt).fit()\n",
    "regressor_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   296.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 02 Jan 2021</td> <th>  Prob (F-statistic):</th> <td>4.53e-30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:28:23</td>     <th>  Log-Likelihood:    </th> <td> -525.39</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1059.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    46</td>      <th>  BIC:               </th> <td>   1066.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.012e+04</td> <td> 6572.353</td> <td>    7.626</td> <td> 0.000</td> <td> 3.69e+04</td> <td> 6.34e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.8057</td> <td>    0.045</td> <td>   17.846</td> <td> 0.000</td> <td>    0.715</td> <td>    0.897</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0268</td> <td>    0.051</td> <td>   -0.526</td> <td> 0.602</td> <td>   -0.130</td> <td>    0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0272</td> <td>    0.016</td> <td>    1.655</td> <td> 0.105</td> <td>   -0.006</td> <td>    0.060</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.838</td> <th>  Durbin-Watson:     </th> <td>   1.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.442</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.949</td> <th>  Prob(JB):          </th> <td>2.21e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.586</td> <th>  Cond. No.          </th> <td>1.40e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.948\n",
       "Method:                 Least Squares   F-statistic:                     296.0\n",
       "Date:                Sat, 02 Jan 2021   Prob (F-statistic):           4.53e-30\n",
       "Time:                        11:28:23   Log-Likelihood:                -525.39\n",
       "No. Observations:                  50   AIC:                             1059.\n",
       "Df Residuals:                      46   BIC:                             1066.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.012e+04   6572.353      7.626      0.000    3.69e+04    6.34e+04\n",
       "x1             0.8057      0.045     17.846      0.000       0.715       0.897\n",
       "x2            -0.0268      0.051     -0.526      0.602      -0.130       0.076\n",
       "x3             0.0272      0.016      1.655      0.105      -0.006       0.060\n",
       "==============================================================================\n",
       "Omnibus:                       14.838   Durbin-Watson:                   1.282\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.442\n",
       "Skew:                          -0.949   Prob(JB):                     2.21e-05\n",
       "Kurtosis:                       5.586   Cond. No.                     1.40e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_opt = x[:, [0, 3, 4, 5]]\n",
    "regressor_ols = sm.OLS(endog = y, exog = x_opt).fit()\n",
    "regressor_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   450.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 02 Jan 2021</td> <th>  Prob (F-statistic):</th> <td>2.16e-31</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:28:59</td>     <th>  Log-Likelihood:    </th> <td> -525.54</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1057.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    47</td>      <th>  BIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.698e+04</td> <td> 2689.933</td> <td>   17.464</td> <td> 0.000</td> <td> 4.16e+04</td> <td> 5.24e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.7966</td> <td>    0.041</td> <td>   19.266</td> <td> 0.000</td> <td>    0.713</td> <td>    0.880</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0299</td> <td>    0.016</td> <td>    1.927</td> <td> 0.060</td> <td>   -0.001</td> <td>    0.061</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.677</td> <th>  Durbin-Watson:     </th> <td>   1.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.939</td> <th>  Prob(JB):          </th> <td>2.54e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.575</td> <th>  Cond. No.          </th> <td>5.32e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 5.32e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.950\n",
       "Model:                            OLS   Adj. R-squared:                  0.948\n",
       "Method:                 Least Squares   F-statistic:                     450.8\n",
       "Date:                Sat, 02 Jan 2021   Prob (F-statistic):           2.16e-31\n",
       "Time:                        11:28:59   Log-Likelihood:                -525.54\n",
       "No. Observations:                  50   AIC:                             1057.\n",
       "Df Residuals:                      47   BIC:                             1063.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.698e+04   2689.933     17.464      0.000    4.16e+04    5.24e+04\n",
       "x1             0.7966      0.041     19.266      0.000       0.713       0.880\n",
       "x2             0.0299      0.016      1.927      0.060      -0.001       0.061\n",
       "==============================================================================\n",
       "Omnibus:                       14.677   Durbin-Watson:                   1.257\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.161\n",
       "Skew:                          -0.939   Prob(JB):                     2.54e-05\n",
       "Kurtosis:                       5.575   Cond. No.                     5.32e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 5.32e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_opt = x[:, [0, 3, 5]]\n",
    "regressor_ols = sm.OLS(endog = y, exog = x_opt).fit()\n",
    "regressor_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = x_opt[:, [1, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9504503015559763"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = LinearRegression()\n",
    "model2.fit(x_new, y)\n",
    "model2.score(x_new, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto Backward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "def backward_eliminations(x, sl):\n",
    "    num_vars = len(x[0])\n",
    "    for i in range(0, num_vars):\n",
    "        reg_ols = sm.OLS(y,x).fit()\n",
    "        max_var = max(reg_ols.pvalues)\n",
    "        if max_var > sl:\n",
    "            for j in range(0, num_vars - i):\n",
    "                if (reg_ols.pvalues[j]==max_var):\n",
    "                    x = np.delete(x, j, 1)\n",
    "    print(reg_ols.summary())\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.000000e+00, 0.000000e+00, 1.000000e+00, 1.653492e+05,\n",
       "       1.368978e+05, 4.717841e+05])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.50406217e-22, 6.04043259e-24, 6.00303972e-02])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_ols.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.947\n",
      "Model:                            OLS   Adj. R-squared:                  0.945\n",
      "Method:                 Least Squares   F-statistic:                     849.8\n",
      "Date:                Sat, 02 Jan 2021   Prob (F-statistic):           3.50e-32\n",
      "Time:                        11:43:27   Log-Likelihood:                -527.44\n",
      "No. Observations:                  50   AIC:                             1059.\n",
      "Df Residuals:                      48   BIC:                             1063.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       4.903e+04   2537.897     19.320      0.000    4.39e+04    5.41e+04\n",
      "x1             0.8543      0.029     29.151      0.000       0.795       0.913\n",
      "==============================================================================\n",
      "Omnibus:                       13.727   Durbin-Watson:                   1.116\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               18.536\n",
      "Skew:                          -0.911   Prob(JB):                     9.44e-05\n",
      "Kurtosis:                       5.361   Cond. No.                     1.65e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.65e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "SL = 0.05\n",
    "X_opt = x[:, [0, 1, 2, 3, 4, 5]]\n",
    "X_Modeled = backward_eliminations(X_opt, SL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00, 1.6534920e+05],\n",
       "       [1.0000000e+00, 1.6259770e+05],\n",
       "       [1.0000000e+00, 1.5344151e+05],\n",
       "       [1.0000000e+00, 1.4437241e+05],\n",
       "       [1.0000000e+00, 1.4210734e+05],\n",
       "       [1.0000000e+00, 1.3187690e+05],\n",
       "       [1.0000000e+00, 1.3461546e+05],\n",
       "       [1.0000000e+00, 1.3029813e+05],\n",
       "       [1.0000000e+00, 1.2054252e+05],\n",
       "       [1.0000000e+00, 1.2333488e+05],\n",
       "       [1.0000000e+00, 1.0191308e+05],\n",
       "       [1.0000000e+00, 1.0067196e+05],\n",
       "       [1.0000000e+00, 9.3863750e+04],\n",
       "       [1.0000000e+00, 9.1992390e+04],\n",
       "       [1.0000000e+00, 1.1994324e+05],\n",
       "       [1.0000000e+00, 1.1452361e+05],\n",
       "       [1.0000000e+00, 7.8013110e+04],\n",
       "       [1.0000000e+00, 9.4657160e+04],\n",
       "       [1.0000000e+00, 9.1749160e+04],\n",
       "       [1.0000000e+00, 8.6419700e+04],\n",
       "       [1.0000000e+00, 7.6253860e+04],\n",
       "       [1.0000000e+00, 7.8389470e+04],\n",
       "       [1.0000000e+00, 7.3994560e+04],\n",
       "       [1.0000000e+00, 6.7532530e+04],\n",
       "       [1.0000000e+00, 7.7044010e+04],\n",
       "       [1.0000000e+00, 6.4664710e+04],\n",
       "       [1.0000000e+00, 7.5328870e+04],\n",
       "       [1.0000000e+00, 7.2107600e+04],\n",
       "       [1.0000000e+00, 6.6051520e+04],\n",
       "       [1.0000000e+00, 6.5605480e+04],\n",
       "       [1.0000000e+00, 6.1994480e+04],\n",
       "       [1.0000000e+00, 6.1136380e+04],\n",
       "       [1.0000000e+00, 6.3408860e+04],\n",
       "       [1.0000000e+00, 5.5493950e+04],\n",
       "       [1.0000000e+00, 4.6426070e+04],\n",
       "       [1.0000000e+00, 4.6014020e+04],\n",
       "       [1.0000000e+00, 2.8663760e+04],\n",
       "       [1.0000000e+00, 4.4069950e+04],\n",
       "       [1.0000000e+00, 2.0229590e+04],\n",
       "       [1.0000000e+00, 3.8558510e+04],\n",
       "       [1.0000000e+00, 2.8754330e+04],\n",
       "       [1.0000000e+00, 2.7892920e+04],\n",
       "       [1.0000000e+00, 2.3640930e+04],\n",
       "       [1.0000000e+00, 1.5505730e+04],\n",
       "       [1.0000000e+00, 2.2177740e+04],\n",
       "       [1.0000000e+00, 1.0002300e+03],\n",
       "       [1.0000000e+00, 1.3154600e+03],\n",
       "       [1.0000000e+00, 0.0000000e+00],\n",
       "       [1.0000000e+00, 5.4205000e+02],\n",
       "       [1.0000000e+00, 0.0000000e+00]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Modeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.950\n",
      "Model:                            OLS   Adj. R-squared:                  0.948\n",
      "Method:                 Least Squares   F-statistic:                     450.8\n",
      "Date:                Sat, 02 Jan 2021   Prob (F-statistic):           2.16e-31\n",
      "Time:                        11:45:40   Log-Likelihood:                -525.54\n",
      "No. Observations:                  50   AIC:                             1057.\n",
      "Df Residuals:                      47   BIC:                             1063.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       4.698e+04   2689.933     17.464      0.000    4.16e+04    5.24e+04\n",
      "x1             0.7966      0.041     19.266      0.000       0.713       0.880\n",
      "x2             0.0299      0.016      1.927      0.060      -0.001       0.061\n",
      "==============================================================================\n",
      "Omnibus:                       14.677   Durbin-Watson:                   1.257\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.161\n",
      "Skew:                          -0.939   Prob(JB):                     2.54e-05\n",
      "Kurtosis:                       5.575   Cond. No.                     5.32e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.32e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "def backwardElimination(x, SL):\n",
    "    numVars = len(x[0])\n",
    "    temp = np.zeros((50,6)).astype(int)\n",
    "    for i in range(0, numVars):\n",
    "        regressor_OLS = sm.OLS(y, x).fit()\n",
    "        maxVar = max(regressor_OLS.pvalues).astype(float)\n",
    "        adjR_before = regressor_OLS.rsquared_adj.astype(float)\n",
    "        if maxVar > SL:\n",
    "            for j in range(0, numVars - i):\n",
    "                if (regressor_OLS.pvalues[j].astype(float) == maxVar):\n",
    "                    temp[:,j] = x[:, j]\n",
    "                    x = np.delete(x, j, 1)\n",
    "                    tmp_regressor = sm.OLS(y, x).fit()\n",
    "                    adjR_after = tmp_regressor.rsquared_adj.astype(float)\n",
    "                    if (adjR_before >= adjR_after):\n",
    "                        x_rollback = np.hstack((x, temp[:,[0,j]]))\n",
    "                        x_rollback = np.delete(x_rollback, j, 1)\n",
    "                        print (regressor_OLS.summary())\n",
    "                        return x_rollback\n",
    "                    else:\n",
    "                        continue\n",
    "    regressor_OLS.summary()\n",
    "    return x\n",
    " \n",
    "SL = 0.05\n",
    "X_opt = x[:, [0, 1, 2, 3, 4, 5]]\n",
    "X_Modeled = backwardElimination(X_opt, SL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
